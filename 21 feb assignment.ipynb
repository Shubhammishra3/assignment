{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abc60a9-c87c-45d8-a69a-40e674f16e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"                             [ assignment]\n",
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\n",
    "answer]Web scraping is the process of collecting structured web data in an automated manner. Itâ€™s also widely known as web \n",
    "data extraction or web data scraping.\n",
    "\n",
    "Some of the main use cases of web scraping include price monitoring, price intelligence, news monitoring, lead generation, \n",
    "and market research among many others. Web scraping is the process of using bots to extract content and data from a website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9256035d-20d1-4bf9-a19a-dbc4a8d9d703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe062f0-95a9-457a-98c1-7dbd4cf87998",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q2. What are the different methods used for Web Scraping?\n",
    "\n",
    "answer]                   Data Scraping Techniques\n",
    " HTML Parsing\n",
    " DOM Parsing\n",
    " Vertical Aggregation\n",
    " XPath\n",
    " Google Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93761291-cd15-4f9e-b8b3-022b301b48d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10657e9e-2512-4e30-aad5-62420033e249",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q3. What is Beautiful Soup? Why is it used?\n",
    "\n",
    "answer] Beautiful Soup is a Python package for parsing HTML and XML documents (including having malformed markup, i.e. \n",
    "non-closed tags, so named after tag soup). It creates a parse tree for parsed pages that can be used to extract data from\n",
    "HTML, which is useful for web scraping.It basically helps in converting data in to human readable form ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef0affe-6028-4294-a8fe-2b4e68da9b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82042e00-9383-4977-8ab6-054c689d7c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q4. Why is flask used in this Web Scraping project?\n",
    "\n",
    "answer] Flask is a lightweight framework to build websites. We'll use this to parse our collected data and display it as HTML\n",
    "in a new HTML file. The requests module allows us to send http requests to the website we want to scrape. The first line \n",
    "imports the Flask class and the render_template method from the flask library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d9093a-fa7d-4481-ac38-42b26bf491b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfb4da8-b0da-4835-81c5-1504c7dac733",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "\n",
    "answer]                             AWS Glue\n",
    "AWS Glue is an extract, transform and load (ETL) service that facilitates data management. It is fully managed and\n",
    "cost-effective, allowing you to classify, clean, enrich, and transfer data. AWS Glue is serverless and includes a Data \n",
    "Catalog, a scheduler and an ETL engine that generates Scala or Python code automatically.\n",
    "                                   Amazon EMR\n",
    "The Amazon EMR managed cluster platform takes most of the complexity out of running big data frameworks like Apache\n",
    "Hadoop and Spark. You can use it to process and analyze big data on AWS resources, including EC2 instances and low cost \n",
    "spot instances. Amazon EMR also allows you to transform and migrate big data between AWS databases (such as DynamoDB)\n",
    "and data stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497b7d50-9cba-4737-b2c4-c319bb50e88c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
